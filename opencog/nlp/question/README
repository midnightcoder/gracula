                          Question Answering
                          ------------------
               Linas Vepstas <linasvepstas@gmail.com>
                        Created 18 March 2008
                        Revised on 13 May 2008
                        Revised on 7 May 2009
                        Revised on 15 September 2009

This directory contains code that implements natural language question
answering via subgraph isomorphism. This README file describes the 
operation and reports on experimental results. The experiments start with
a fairly simple question-answering technique, which, although functional,
is not very robust. The basic idea is that NL parses of assertions, such
as "John threw the ball", and questions, such as "Who threw the ball?"
resemble each other quite closely. One need only recognize "who" as an
implicit variable name, and then search over the entire atomspace to 
find a matching pattern, at which point the word "John" can be used 
as a grounding for the variable "who?". Additonal experiments examine
increasingly more complex strategies.

Four sets of experiments are reported: pattern matching at the RelEx
level, pattern matching at the framenet level, pattern matching at 
the "semantic triples" level, and using predicate structures for 
sophisticated question processing. The RelEx level represents sentences
as collections of subject, object relations, together with noun number, 
verb tense, etc. markup.  The Frame level decorates the basic RelEx 
relations with situational context infered from the sentences. The
"semantic triples" normalize syntactic relations into "semantic-web"
style relational triples.  Finally, "question comprehension" recognizes
the structure of questions themselves, and respond to that structure.

XXXXXX As of 13 May 2008, changes to the RelEx output have broken the 
operation of the frame-query part of this code. As of 23 April 2009,
the simpler RelEx query style has been restored and now works again. 
As of August 2009, things are kind of broken again. As of September
2009, all of the C++ code has been deprecated, and various parts have
been removed.  A new, far superior implementation has been created in
a combination of scheme and pattern-matching, in the nlp/triples and
the nlp/seme directories.  The new implemention now powers the chatbot.

Because of this, the C++ code in this directory is no longer being
built or maintained. It is not being deleted, not just yet -- its of
some historical interest (to me, Linas), as it provides an example of
why C++ sucks for any non-core OpenCog info processing.  Also, this
README file should never be deleted, but should be permanently archived,
as it provides concrete documentation of (early) research results.
XXXXXX

General conclusion: while superficial question answering is possible, 
a robust system remains difficult.  Work continues (very slowly) along
several directions, and/or should explore several ideas: (1) identify
synonymous phrases, as described by Lin & Patel [Lin2001]. (2) Continue
work on "semantic normalization", along the lines of the "semantic 
triples" work described in nlp/triples/README. (3) Pursue use of PLN
for answer-generation (4) Pursue work on "question comprehension".

* [Lin2001] Dekang Lin and Patrick Pantel. 2001.  "Discovery of Inference
  Rules for Question Answering." ''Natural Language Engineering'' 
  '''7'''(4):343-360.  http://www.cs.ualberta.ca/~lindek/papers/jnle01.pdf 

Question Answering Overview
---------------------------
Currently, the question answering code dependings on a processing
pipeline

 -- Input of English language sentences
 -- parsing by Link Grammar parser
 -- dependency relations built by RelEx
 -- framenet context built by RelEx
 -- import into OpenCog
 -- semantic triple extraction within opencog
 -- "question comprehension" within opencog
 -- NL generation, English output.

The "chatbot" (nlp/chatbot/README) provides the overall systems 
integration that allows this pipeline to function.

Four approaches to question-answering are considered below. These all
make use of pattern-matching in one way or another; they differ in the
kinds of patterns that are searched for, and the sophistication of the 
pattens themselves.  These are:

 -- Pattern matching of RelEx dependency grammar expressions
 -- Pattern matching of FrameNet context frames
 -- Pattern matching on "semantic triples"
 -- "Question comprehension" by extracting question patterns

Query processing at the RelEx level provides only a very narrow, literal
answer; there is very little "wiggle room" or ability to understand the
nature of the question.  Thus, for example, the question "What did John
throw?" is represented by the RelEx dependency-grammar as

    _subj(throw, John )
    _obj(throw, _$qVar)

To answer this question, the OpenCog atomspace must contain a sentence
that had parsed into exactly the above form. For this example, the 
atomspace must contain the dependency parse for the sentence "John
threw a ball"

    _subj(throw, John )
    _obj(throw, ball)

From this, one can immediately induce that _$qVar == ball and thus the
answer is "ball".  This level of pattern matching fails when the
question has a different syntactic structure than the answer: for
example: "What is the thing that John threw?"

    _subj(throw, John)
    _obj(throw, thing) 
    _subj(be, _$qVar) 
    _obj(be, thing)

This question asserts that John threw a thing, and simultaneously asks
what that thing is. The dependency-grammar graph of the question is
completely different than the answer.  Thus, a more abstract 
representation of both the question, and the answer, is needed.

One attempt at this abstraction is to decorate the basic parse with
FrameNet-style contextual markup.  Unfortunately, the markup that is
provided by RelEx is not very accurate, and introduces a lot of "noise"
into the overall structure. Properly matching in the presence of this
noise appears to be difficult.  Thus, some kind of mechanism, outside
of the scope of query processing, seems to be required to firm up the
accuracy of the context frames.

An alternate attempt at this abstraction is to convert dependency parses
into "semantic triples", similar in structure to John Sowa's "conceptual
nets", or the broader notion of the "semantic web".  This is 
(superficially) promising because it can re-express direct statements
into semantic or ontological relations; these can be operated on by 
theorem provers, resoning systems, etc. So, for example, both "Berlin
is the capital of Germany" and "The capital of Germany is Berlin" can
be expressed as a triple "capital_of(Germany,Berlin)", even though the
two dependency parses are quite different.  Furthermore, direct 
assertions such as this can be directly compared to databases of 
retained knowledge about capitals, countries and cities.  Simple
pattern matching can work, becuase "What is the capital of Germany?"
becomes "capital_of(Germany, _$qVar)"

However, even this approach fails for more complex questions, and even
questions as simple as yes/no questions: "Is Berlin the capital of 
Germany?"  This is because there are no explicit, bound variables in
the question (no "who/what/where/why/when") to resolve.  The truth-query
question is a hypothetical statement, asking for the truth of the
hypothesis. Forward progress here depends on "question comprehension":
on recognizing the structure of the question, analyzing what it is
asking for, and only then attempting to find an answer.


RelEx Dependency Parse Pattern Matching
---------------------------------------
A detailed example of using RelEx dependency parses to provide answers
by relationship matching follows.

"John threw a ball."

    _subj(throw, John)
    _obj(throw, ball)
    tense(throw, past)
    noun_number(ball, singular)
    DEFINITE-FLAG(John, T)
    noun_number(John, singular)

"What did John throw?"

    _subj(throw, John)
    _obj(throw, _$qVar)
    tense(throw, past_infinitive)
    HYP(throw, T)
    QUERY-TYPE(_$qVar, what)
    DEFINITE-FLAG(John, T)
    noun_number(John, singular)

Eliminate the HYP and QUERY-TYPE from the question, since
the answer will never contain these. One is left with:

    _subj(throw, John)
    _obj(throw, _$qVar)
    tense(throw, past_infinitive)
    DEFINITE-FLAG(John, T)
    noun_number(John, singular)

Clearly, the RelEx pattern of the question can be matched to 
the RelEx pattern of the answer, to find that _$qVar == ball.
(Some twiddling required to match tense correctly).
This type of RelEx relation-level setup, query massaging 
and node matching is implemented in SentenceQuery.cc, SentenceQuery.h
It seems to work, but hasn't undergone strenuous testing.

Pattern matching at the RelEx level is not always possible, as shown
next. At the root of the problem is that RelEx provides only a small
amount of "semantic normalization". That is, RelEx will abstract 
(pull out, normalize) some, but not much, semantics.  Similar 
statements will be similar, whereas the query processor is looking for
exact matches, and not merely similarities.  Thus, query processing
will fail without exact matches. A mechanism will be needed for handling
"similar" statements with similar meanings.

Copula troubles:
----------------
Intensional/extensional inheritance causes problems for 
simple RelEx matching.

Yarn is a length of fibers.
    _subj(be, yarn)
    _obj(be, length)
    tense(be, present)
    of(length, fiber)
    noun_number(length, singular)
    noun_number(fiber, plural)
    noun_number(yarn, uncountable)

Yarn is what?
(fails to parse in current link-grammar)

What is yarn?

    _subj(be, _$qVar)
    _obj(be, yarn)
    tense(be, present)
    noun_number(yarn, uncountable)
    COPULA-QUESTION-FLAG(yarn, T)
    QUERY-TYPE(_$qVar, what)
    noun_number(_$qVar, uncountable)

Note that the _subj and _obj are exchanged in the query, 
preventing a direct match.


Frame matching
--------------
The goal of working with frames rather than RelEx relations is
to escape from the strictures of the syntactic relations, and
move to a more semantic interpretation.

Yarn is a length of fibers.

    ^1_Categorization:Category(be,length)
    ^1_Existance:Entity(be,yarn)
    ^2_Inheritence:Quality(of,length)
    ^2_Inheritence:Inheritor(of,fiber)
    ^2_Inheritence:Group(of,fiber)
    ^2_Inheritence:Instance(of,length)
    ^1_Partitive:Subset(of,length)
    ^1_Partitive:Group(of,fiber)
    ^1_Part_whole:Part(of,length)
    ^1_Part_whole:Whole(of,fiber)
    ^1_Physical_entity:Constituents(of,fiber)
    ^1_Physical_entity:Entity(of,length)
    ^1_Categorization:Item(be,yarn)
    ^1_Temporal_colocation:Time(present,be)
    ^1_Temporal_colocation:Event(present,be)


What is yarn?

    ^1_Existance:Entity(be,_$qVar)
    ^1_Categorization:Category(be,yarn)
    ^1_Temporal_colocation:Time(present,be)
    ^1_Temporal_colocation:Event(present,be)
    ^1_Categorization:Item(be,_$qVar)
    ^1_Entity:Entity(what,_$qVar)
    ^1_Questioning:Message(what,_$qVar)
    ^1_Attributes:Entity(what,_$qVar)

Trim the question to remove references to questioning (as the answer
won't possess these). Remove the "what" part as well. The question
becomes:

    ^1_Categorization:Category(be,yarn)
    ^1_Temporal_colocation:Time(present,be)
    ^1_Temporal_colocation:Event(present,be)
    ^1_Categorization:Item(be,_$qVar)
    ^1_Existance:Entity(be,_$qVar)

The goal of pattern matching is to glue (i.e. pattern-match) 
the above five clauses onto the original assertion that 
"yarn is a length of fibers".

The glueing fails. I want to get the answer that $qVar == length.
But I cannot match up ^1_Existance:Entity(be,_$qVar)
to ^1_Existance:Entity(be,length) --

Next, I want to match up ^1_Categorization:Category(be,yarn),
(from the question) to ^1_Categorization:Item(be,yarn) (from
the answer) but I can't. 

This asymmetry of the question and its answer has me blocked.

The root problem seems to be that both

    _subj(be, _$qVar)
    _obj(be, yarn)

and

    _obj(be, _$qVar)
    _subj(be, yarn)

are valid forms for the question. The second one should be
more common, but its not the one being generated. There 
should probably be a frame rule to reverse this order.

Alternately: perhaps triples processing (discussed below) should be
done *before* frame annotation.

============
Step back; look at frame matching in a simpler example.

John threw a ball. 
    ^1_Body_movement:Agent(throw,John)
    ^1_Cause_motion:Theme(throw,ball)
    ^1_Transitive_action:Agent(throw,John)
    ^1_Temporal_colocation:Event(past,throw)
    ^1_Temporal_colocation:Time(past,throw)
    ^1_Body_movement:Body_part(throw,ball)
    ^1_Cause_motion:Cause(throw,John)
    ^1_Transitive_action:Object(throw,ball)


What did John throw?

    ^1_Body_movement:Agent(throw,John)
    ^1_Cause_motion:Theme(throw,_$qVar)
    ^1_Transitive_action:Agent(throw,John)
    ^1_Entity:Entity(what,_$qVar)
    ^1_Questioning:Message(what,_$qVar)
    ^1_Attributes:Entity(what,_$qVar)
    ^1_Possibilites:Event(hyp,throw)
    ^1_Body_movement:Body_part(throw,_$qVar)
    ^1_Cause_motion:Cause(throw,John)
    ^1_Transitive_action:Object(throw,_$qVar)


Remove "Questioning" and "what".

    ^1_Body_movement:Agent(throw,John)          -- OK match
    ^1_Cause_motion:Theme(throw,_$qVar)         -- OK _$qVar == ball
    ^1_Transitive_action:Agent(throw,John)      -- OK match
    ^1_Body_movement:Body_part(throw,_$qVar)    -- OK _$qVar == ball
    ^1_Cause_motion:Cause(throw,John)           -- OK match
    ^1_Transitive_action:Object(throw,_$qVar)   -- OK _$qVar == ball

This type of RelEx frame-level setup, query massaging 
and node matching is implemented in FrameQuery.cc, FrameQuery.h
It seems to work, but hasn't undergone strenuous testing.

Note, however, for this simpler case, frame-matching provides no 
advantage over parse matching.

Testing
-------
Some test corpus material, and test results:

====
Mike threw a rock.
John threw a ball and a screwdriver.
John ate a peach.
What did John throw?

RelEx matching provides two correct answers: 
_$qVar = ball, and _$qVar = screwdriver.
====

The book is red. What color is the book?
The color of the book is red. What color is the book?

Both of these fail on the simple pattern match. However, the triples
processing (describe below) can answer "What is the color of the book?"
It still fails on "What color is the book?" because of the missing 
preopostion "of".

====
Yarn is a length of fibers.
What is yarn?

Fails, as discussed above
====
Yarn is used to make cloth.
What is yarn used for?

    _to-do(use, make)
    _obj(use, yarn)
    tense(use, present)
    _subj(make, yarn)
    _obj(make, cloth)
    tense(make, infinitive)
    HYP(make, T)
    noun_number(cloth, uncountable)
    noun_number(yarn, uncountable)

The assertion has a second parse, with "to" instead of "_to-do"

The question has three parses. The first is:

    for(use, for)
    _obj(use, yarn)
    tense(use, present)
    _amod(for, use)
    _obj(for, _$qVar)
    tense(for, present)
    noun_number(yarn, uncountable)

All three parses contain _obj(use, yarn), and that's good.

Clearly, the pattern match here fails. All three parses contain
_obj(for, _$qVar) which cannot be matched to the original assertion.

All three contain either _amod(for, use) or _amod(for, be)
and these _amod's cannot be matched to the original assertion.

The frame situation is no better.  The assertion frame is:
 
    ^1_Transitive_action:Agent(make,yarn)
    ^1_Ingest_substance:Substance(use,yarn)
    ^1_Intentionally_create:Creator(make,yarn)
    ^1_Using:Instrument(use,yarn)
    ^1_Building:Created_entity(make,cloth)
    ^1_Causation:Affected(make,yarn)
    ^1_Arriving:Theme(make,yarn)
    ^1_Causation:Effect(make,cloth)
    ^1_Ingest_substance:Purpose(use,make)
    ^1_Cause_change:Cause(make,yarn)
    ^1_Possibilites:Event(hyp,make)
    ^1_Using:Purpose(use,make)
    ^1_Arriving:Goal(make,cloth)
    ^1_Temporal_colocation:Time(present,use)
    ^1_Temporal_colocation:Event(present,use)
    ^1_Transitive_action:Cause(verb,use)
    ^1_Transitive_action:Event(verb,make)
    ^1_Cooking_creation:Cook(make,yarn)
    ^1_Building:Agent(make,yarn)
    ^1_Cooking_creation:Produced_food(make,cloth)
    ^1_Intentionally_create:(make,cloth)
    ^1_Transitive_action:Object(make,cloth)
    ^1_Transitive_action:Object(use,yarn)
    ^1_Manufacturing:Product(make,cloth)
    ^1_Manufacturing:Factory(make,yarn)
    ^1_Cause_change:Entity(make,cloth)

The appearance of "cooking" is unexpected.  "Building" is odd 
Why not "manufacture" or "intentionally_create"?

"Ingest" is ... and odd way of saying that the yarn is used up...

  "What is yarn used for?"

Has the frameset below.  I've manually removed Questioning:Message, 
etc. as these are explicitly ignored for the question pattern match.
I've marked up each according to whether the frames echoed the
assertion:


    ^1_Using:Purpose(use,for)                         -- no match
    ^1_Ingest_substance:Substance(use,yarn)           == OK
    ^1_Using:Instrument(use,yarn)                     == OK
    ^1_Relative_time:Focal_occasion(for,for)          -- no match
    ^1_Relative_time:Landmark_occasion(for,use)       -- no match
    ^1_Temporal_colocation:Time(present,use)          == OK
    ^1_Temporal_colocation:Event(present,use)         == OK
    ^1_Temporal_colocation:Event(present_1,for)       -- no match
    ^1_Temporal_colocation:Time(present_1,for)        -- no match
    ^1_Ingest_substance:Purpose(use,for)              -- no match
    ^1_Transitive_action:Object(for,_$qVar)           -- no match
    ^1_Transitive_action:Object(use,yarn)             == OK

The word "for" seems to lie at the root of the problem.  
Lets try a different assertion:

  "Yarn is used for making cloth."

A clause by clause comparison shows that this doesn't match
the question any better then before. So pattern matching the
question fails here too.  

How similar are the two assertions? Lets compare RelEx output first;
ignoring tense, noun_number, which are correct, we have:

  "Yarn is used for making cloth."
    _obj(use, yarn)
    _amod(for, use)
    _subj(make, for)
    _obj(make, cloth)

  "Yarn is used to make cloth."
    _to-do(use, make)
    _obj(use, yarn)
    _subj(make, yarn)
    _obj(make, cloth)
    HYP(make, T)

The only agreement is that both correctly state _obj(make, cloth)
and _obj(use, yarn)  However, _subj in both is confusing, and 
it seems hard to induce that the thing being used is also the 
input to the thing being made.

  "Yarn is used in making cloth."

    _obj(use, yarn)
    _amod(in, use)
    _subj(make, in)
    _obj(make, cloth)

  "Yarn is used in the making of cloth."

    in(use, making)
    _obj(use, yarn)
    of(making, cloth)

The frame rules do not seem to introduce more commonality
between these; rather, they seem to diverge even more. Thus,
instead of the frames making things seem "more semantically
similar", they seem to do the opposite.

Now, some sort of fuzzy matching could be done here, since there
is clearly some non-zero overlap between all of these. Even more
so: it seems like the common parts of all of these ways of saying 
this capture the "underlying truth" the best. But without a large 
corpus, without lots of activation, and repeated similar but not 
identical restatements of the same ideas, I don't see any particularly
good ways of inducing that yarn is used to make cloth...

Triples matching
----------------
The discussion of question-answering via sentence templates continues
in the file nlp/triples/README and nlp/triples/README-sentences. The
first file reviews the core concept of the semantic triple, and the
machinery needed to construct these within OpenCog.  The second file
continues by analyzing various specific types of declarations and 
questions, including copulas and yes/no questions.


References
----------
See:
http://www.cs.ualberta.ca/~lindek/papers.htm
Dekang Lin and Patrick Pantel. 2001. Discovery of Inference Rules for
Question Answering. Natural Language Engineering 7(4):343-360. [PDF][PS]

See also:
DIRT - Discovery of Inference Rules from Text, Dekang Lin and Patrick Pantel.

Syntactic and Semantic Decomposition Strategies for Question
Answering from Multiple Resources
Boris Katz, Gary Borchardt and Sue Felshin
Proceedings of the AAAI 2005 Workshop on Inference 2005 - aaai.org

TODO
----
 * Parts of the system are still using WordNodes, when they should be
   using SemeNodes. See, for example WordRelQuery.cc. The WordNode's
   should be removed.

 * Code here still uses the old implication interface, should use the
   new VariableScope interface (and/or ForAll, ThereExists, etc). The
   goal is to explicitly declare the variables.

 
